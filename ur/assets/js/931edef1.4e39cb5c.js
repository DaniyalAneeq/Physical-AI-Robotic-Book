"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[931],{6831:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"bookSidebar":[{"type":"category","label":"Module 1: The Robotic Nervous System (ROS 2)","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/Physical-AI-Robotic-Book/ur/docs/module1/chapter1","label":"Introduction to ROS 2","docId":"module1/chapter1","unlisted":false},{"type":"link","href":"/Physical-AI-Robotic-Book/ur/docs/module1/chapter2","label":"ROS 2 Nodes, Topics, and Messages","docId":"module1/chapter2","unlisted":false},{"type":"link","href":"/Physical-AI-Robotic-Book/ur/docs/module1/chapter3","label":"ROS 2 Services and Actions: Request/Reply and Long-Running Tasks","docId":"module1/chapter3","unlisted":false},{"type":"link","href":"/Physical-AI-Robotic-Book/ur/docs/module1/chapter4","label":"Parameters and TF2: Configuration and Coordinate Frames","docId":"module1/chapter4","unlisted":false},{"type":"link","href":"/Physical-AI-Robotic-Book/ur/docs/module1/chapter5","label":"Robot Description and Gazebo Simulation","docId":"module1/chapter5","unlisted":false},{"type":"link","href":"/Physical-AI-Robotic-Book/ur/docs/module1/chapter6","label":"ROS 2 Navigation Stack Fundamentals","docId":"module1/chapter6","unlisted":false}],"href":"/Physical-AI-Robotic-Book/ur/docs/category/module-1-the-robotic-nervous-system-ros-2"},{"type":"category","label":"Module 2: Embodied AI with Advanced Simulations","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/Physical-AI-Robotic-Book/ur/docs/module2/chapter1-intro-digital-twins","label":"Introduction to Digital Twins: Gazebo & Unity","docId":"module2/chapter1-intro-digital-twins","unlisted":false},{"type":"link","href":"/Physical-AI-Robotic-Book/ur/docs/module2/chapter2-gazebo-physics","label":"Advanced Simulation in Gazebo: Physics and Environments","docId":"module2/chapter2-gazebo-physics","unlisted":false},{"type":"link","href":"/Physical-AI-Robotic-Book/ur/docs/module2/chapter3-unity-environments","label":"Environment Building in Unity: Scenes and Robots","docId":"module2/chapter3-unity-environments","unlisted":false},{"type":"link","href":"/Physical-AI-Robotic-Book/ur/docs/module2/chapter4-sensor-simulation","label":"Advanced Sensor Simulation","docId":"module2/chapter4-sensor-simulation","unlisted":false},{"type":"link","href":"/Physical-AI-Robotic-Book/ur/docs/module2/chapter5-humanoid-digital-twin","label":"Building a Full Humanoid Digital Twin","docId":"module2/chapter5-humanoid-digital-twin","unlisted":false}],"href":"/Physical-AI-Robotic-Book/ur/docs/category/module-2-embodied-ai-with-advanced-simulations"},{"type":"category","label":"Module 3: The AI-Robot Brain (NVIDIA Isaac\u2122)","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/Physical-AI-Robotic-Book/ur/docs/module3/introduction-to-isaac-sim","label":"Chapter 1: Introduction to NVIDIA Isaac Sim","docId":"module3/introduction-to-isaac-sim","unlisted":false}],"href":"/Physical-AI-Robotic-Book/ur/docs/category/module-3-the-ai-robot-brain-nvidia-isaac"},{"type":"category","label":"Module 4: Vision-Language-Action (VLA)","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/Physical-AI-Robotic-Book/ur/docs/module4/introduction-to-vla","label":"Introduction to Vision-Language-Action (VLA)","docId":"module4/introduction-to-vla","unlisted":false},{"type":"link","href":"/Physical-AI-Robotic-Book/ur/docs/module4/whisper-voice-to-action","label":"Whisper Voice-to-Action Pipeline","docId":"module4/whisper-voice-to-action","unlisted":false},{"type":"link","href":"/Physical-AI-Robotic-Book/ur/docs/module4/llm-cognitive-planning","label":"LLM-based Cognitive Planning for Robotics","docId":"module4/llm-cognitive-planning","unlisted":false},{"type":"link","href":"/Physical-AI-Robotic-Book/ur/docs/module4/vision-grounded-action","label":"Vision-Grounded Action Understanding","docId":"module4/vision-grounded-action","unlisted":false},{"type":"link","href":"/Physical-AI-Robotic-Book/ur/docs/module4/integrated-vla-humanoid-pipeline","label":"Integrated VLA Humanoid Pipeline","docId":"module4/integrated-vla-humanoid-pipeline","unlisted":false}],"href":"/Physical-AI-Robotic-Book/ur/docs/category/module-4-vision-language-action-vla"},{"type":"link","href":"/Physical-AI-Robotic-Book/ur/docs/glossary","label":"Glossary","docId":"glossary","unlisted":false},{"type":"link","href":"/Physical-AI-Robotic-Book/ur/docs/notation","label":"Notation","docId":"notation","unlisted":false},{"type":"link","href":"/Physical-AI-Robotic-Book/ur/docs/intro","label":"\ud83d\udcd8 Introduction to the Physical AI & Humanoid Robotics Course","docId":"intro","unlisted":false}]},"docs":{"glossary":{"id":"glossary","title":"Glossary","description":"This glossary defines common terms used throughout the textbook to ensure consistency.","sidebar":"bookSidebar"},"intro":{"id":"intro","title":"\ud83d\udcd8 Introduction to the Physical AI & Humanoid Robotics Course","description":"Humanoid robotics is entering a new era\u2014an era where AI models are no longer confined to screens, but instead act through bodies, interact with humans, and perform tasks in the physical world.","sidebar":"bookSidebar"},"module1/chapter1":{"id":"module1/chapter1","title":"Introduction to ROS 2","description":"Learning Objectives","sidebar":"bookSidebar"},"module1/chapter2":{"id":"module1/chapter2","title":"ROS 2 Nodes, Topics, and Messages","description":"Learning Objectives","sidebar":"bookSidebar"},"module1/chapter3":{"id":"module1/chapter3","title":"ROS 2 Services and Actions: Request/Reply and Long-Running Tasks","description":"Learning Objectives","sidebar":"bookSidebar"},"module1/chapter4":{"id":"module1/chapter4","title":"Parameters and TF2: Configuration and Coordinate Frames","description":"Learning Objectives","sidebar":"bookSidebar"},"module1/chapter5":{"id":"module1/chapter5","title":"Robot Description and Gazebo Simulation","description":"Learning Objectives","sidebar":"bookSidebar"},"module1/chapter6":{"id":"module1/chapter6","title":"ROS 2 Navigation Stack Fundamentals","description":"Learning Objectives","sidebar":"bookSidebar"},"module2/chapter1-intro-digital-twins":{"id":"module2/chapter1-intro-digital-twins","title":"Introduction to Digital Twins: Gazebo & Unity","description":"Learning Objectives","sidebar":"bookSidebar"},"module2/chapter2-gazebo-physics":{"id":"module2/chapter2-gazebo-physics","title":"Advanced Simulation in Gazebo: Physics and Environments","description":"Learning Objectives","sidebar":"bookSidebar"},"module2/chapter3-unity-environments":{"id":"module2/chapter3-unity-environments","title":"Environment Building in Unity: Scenes and Robots","description":"Learning Objectives","sidebar":"bookSidebar"},"module2/chapter4-sensor-simulation":{"id":"module2/chapter4-sensor-simulation","title":"Advanced Sensor Simulation","description":"Learning Objectives","sidebar":"bookSidebar"},"module2/chapter5-humanoid-digital-twin":{"id":"module2/chapter5-humanoid-digital-twin","title":"Building a Full Humanoid Digital Twin","description":"Learning Objectives","sidebar":"bookSidebar"},"module3/introduction-to-isaac-sim":{"id":"module3/introduction-to-isaac-sim","title":"Chapter 1: Introduction to NVIDIA Isaac Sim","description":"NVIDIA Isaac Sim is a powerful, extensible, and physically accurate open platform for robotics simulation built on NVIDIA Omniverse. It enables the development, testing, and deployment of AI-powered robots by providing a highly realistic virtual environment.","sidebar":"bookSidebar"},"module4/integrated-vla-humanoid-pipeline":{"id":"module4/integrated-vla-humanoid-pipeline","title":"Integrated VLA Humanoid Pipeline","description":"In this final chapter, we will bring everything together to build a complete end-to-end VLA pipeline for a humanoid robot.","sidebar":"bookSidebar"},"module4/introduction-to-vla":{"id":"module4/introduction-to-vla","title":"Introduction to Vision-Language-Action (VLA)","description":"Welcome to the exciting world of Vision-Language-Action (VLA) models! In this chapter, we will explore the fundamental concepts of VLA and its significance in modern robotics.","sidebar":"bookSidebar"},"module4/llm-cognitive-planning":{"id":"module4/llm-cognitive-planning","title":"LLM-based Cognitive Planning for Robotics","description":"In this chapter, we dive into using Large Language Models (LLMs) to transform natural language instructions into structured, executable ROS 2 action sequences for robots.","sidebar":"bookSidebar"},"module4/vision-grounded-action":{"id":"module4/vision-grounded-action","title":"Vision-Grounded Action Understanding","description":"This chapter focuses on integrating multimodal perception models for grounded object recognition and contextual understanding.","sidebar":"bookSidebar"},"module4/whisper-voice-to-action":{"id":"module4/whisper-voice-to-action","title":"Whisper Voice-to-Action Pipeline","description":"In this chapter, we will build a voice command recognition system using OpenAI\'s Whisper model and integrate it into a ROS 2 framework.","sidebar":"bookSidebar"},"notation":{"id":"notation","title":"Notation","description":"This page defines the mathematical notation used in the textbook.","sidebar":"bookSidebar"}}}}')}}]);